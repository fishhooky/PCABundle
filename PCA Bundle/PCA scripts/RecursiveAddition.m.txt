function output = VariableOptimisation(training,test,R1,R2,PCS)
%% Creation of sparse variable set for PCA
% Removes the number of X-variables within a dataset
% Recursive feature elimination
% Optimisation based upon separation of different samples and training and test datasets
% Sample order for training and test sets must be the same
% Different samples in different rows
% Different variables in different columns
% Andrew Hook June 2019

%% Setup
data1 = training;
t= test;
%R1 = 7; % Number of replicates within training set
%R2 = 3; % Number of replicates within test set
S1 = floor(size(data1,1)/R1); % Number of different sample sets
c1 = 1; % Coefficient for weighting of differences between samples
c2 = 1; % Coefficient for weighting of differences between test and training
%PCS = [1 2]; % Array of principal components of interest
output=[];

CF = questdlg('Cost function method?','Select','Maximise separation','Minimise overlap','Maximise separation'); % select cost function method

%% Calculate values for whole dataset
[coeff,score,latent,tsquared,explained,mu] = pca(data1);
TestScores=(t-mu)*coeff;
% Calculate average score for each sample for each PC
data3(3,S1,size(PCS,2))=0;
data3(:,:)=0;
for x3 = 1:S1
    for x4 = 1:size(PCS,2)
        data3(1,x3,x4)=mean(score(1+R1*(x3-1):x3*R1,PCS(1,x4)));
    end
end

% Calculate average distance between samples
data4=[];
data4(1:S1,1:S1)=0;
for x3 = 1:S1
    for x4 = 1:S1
        for x5 = 1:size(PCS,2)
            data4(x3,x4)=data4(x3,x4)+abs(data3(1,x3,x5)-data3(1,x4,x5));
        end
        %data4(x3,x4)=data4(x3,x4)^0.5;
    end
    data3(2,x3,1)=sum(data4(x3,:));
end

% Calculate average distance between training and test sets
data4 = [];
data4(R2)=0;
for x3 = 1:S1
    for x4 = 1:R2
        for x5 = 1:size(PCS,2)
            data4(x4)=data4(x4)+abs(TestScores(x4+R2*(x3-1),x5)-data3(1,x3,x5));
        end
        %data4(x4)=data4(x4)^0.5;
    end
    data3(3,x3,1)=sum(data4);
    data4(:)=0;
end
dataX=data3(2:3,1:S1);

% Calculate number of test datapoint outside 95% confidence limit
data4 =[];data5=[];
data4=score(:,PCS(1));
data5=TestScores(:,PCS(1));
for x3 = 2:size(PCS,2) % loop for different PCS
    data4(:,2)=score(:,PCS(1,x3));
    data5(:,2)=TestScores(:,PCS(1,x3));
    [M1,M2]=GetEllipses(data4,R1,data5,R2);
    dataX(1+x3,1:S1)=transpose(R2-sum(M2,2)); % Add number of points outside confidence limit
end
M2=[];data5=[];
%% Loop for removing variables
for x1 = 1:size(training,2)-2
    for x2 = 1:size(data1,2)
        data3=[];
        if size(find(data1(:,x2)==0),1)~=size(data1,1) % Selection to end analysis early if everything has been nulled
            % Sequentially select dataset with one less variable
            if x2==1
                data2 = data1(:,2:end);
                t1=t(:,2:end);
            elseif x2 == size(data1,2)
                data2 = data1(:,1:end-1);
                t1=t(:,1:end-1);
            else
                data2=data1(:,1:x2-1);
                t1=t(:,1:x2-1);
                data2(:,x2:size(data1,2)-1)=data1(:,x2+1:end);
                t1(:,x2:size(data1,2)-1)=t(:,x2+1:end);
            end
            
            %Run PCA
            [coeff,score,latent,tsquared,explained,mu] = pca(data2,'NumComponents',max(PCS));
            %Apply to test dataset
            TestScores=(t1-mu)*coeff;
            
            % Determine if test set within 95% confidence of training set
            data5=score(:,PCS(1));
            data6=TestScores(:,PCS(1));
            for x3=2:size(PCS,2)
                data5(:,2)=score(:,PCS(x3));
                data6(:,2)=TestScores(:,PCS(x3));
                [M1,M2(1:S1,1+(x3-2)*R2:R2*(x3-1))]=GetEllipses(data5,R1,data6,R2);
            end
            
            % Count number of test datapoints outside confidence limit
            for x3=1:size(PCS,2)-1
                M2(:,x3)=R2-sum(M2(:,1+R2*(x3-1):R2*x3),2);
            end
            M2(:,x3+1:end)=[];
            M2=transpose(M2); % Transform M2 to allow comparison with dataX
            
            % Calculate average score for each sample for each PC
            data3(3,S1,size(PCS,2))=0;
            data3(:,:)=0;
            for x3 = 1:S1
                for x4 = 1:size(PCS,2)
                    data3(1,x3,x4)=mean(score(1+R1*(x3-1):x3*R1,PCS(1,x4)));
                end
            end
            
            % Calculate test score for optimisation
            data4=[];
            data4(1:S1,1:S1)=0;
            if strcmp(CF,'Minimise overlap')==1 && size(PCS,2)>1% calculation based upon minimising ellipse overlap, if not true will fine average separation of means
                for x3=1:floor(size(PCS,2)/2)
                    data4=[];
                    data4(:,1)=score(:,1+(x3-1)*2);
                    data4(:,2)=score(:,2+(x3-1)*2);
                    Ellipse = GetEllipses(data4,R1); % find ellipses
                    for x4=1:S1 %find max and min coordinates
                       data5(1,x4)=max(Ellipse(:,1+(x4-1)*2)); %max X
                       data5(2,x4)=max(Ellipse(:,x4*2));% max Y
                       data5(3,x4)=min(Ellipse(:,1+(x4-1)*2)); %min X
                       data5(4,x4)=min(Ellipse(:,x4*2)); %min y
                    end
                    maxX=max(data5(1,:));minX=min(data5(3,:));
                    maxY=max(data5(2,:));minY=min(data5(4,:));
                    for x4=1:S1 % transpose data onto range 1 to 100
                        Ellipse(:,1+2*(x4-1))=round((Ellipse(:,1+2*(x4-1))-minX)/(maxX-minX)*99)+1;
                        Ellipse(:,2*x4)=round((Ellipse(:,2*x4)-minY)/(maxY-minY)*99)+1;
                    end
                    data5=zeros(100,100);
                    areas=zeros(S1,2);
%                     f1=figure;hold on
%                     f2=figure;
                    for x4=1:S1 % mark pixels associated with each ellipse
%                         figure(f1);hold on
%                         plot(Ellipse(:,1+2*(x4-1)),Ellipse(:,2*x4))
                        Ellipse(:,2*x4)=101-Ellipse(:,2*x4);                        
                        for x5=min(Ellipse(:,2*x4)):max(Ellipse(:,2*x4))
                            data6=find(Ellipse(:,2*x4)==x5);
                            minY=min(Ellipse(data6,1+(x4-1)*2));
                            maxY=max(Ellipse(data6,1+(x4-1)*2));
                            data5(x5,minY:maxY)=data5(x5,minY:maxY)+1;
                            if size(maxY,1)>0
                                areas(x4,1)=areas(x4,1)+1+maxY-minY;
                            else
                                areas=areas;
                            end
                        end
%                         figure(f2);imshow(data5)
                    end
                    for x4=1:S1 % mark pixel areas that overlap
                        for x5=min(Ellipse(:,2*x4)):max(Ellipse(:,2*x4))
                            data6=find(Ellipse(:,2*x4)==x5);
                            minY=min(Ellipse(data6,1+(x4-1)*2));
                            maxY=max(Ellipse(data6,1+(x4-1)*2));                            
                            if size(maxY,1)>0
                                areas(x4,2)=areas(x4,2)+size(find(data5(x5,minY:maxY)==1),2);
                            end
                        end
                    end
%                     areas(10,2)=areas(10,2)*5;% Bias sample 10
%                     areas(1:3,2)=areas(1:3,2)*3;
%                     areas(5,2)=areas(5,2)*3;
%                     areas(7,2)=areas(7,2)*3;
                    %data3(2,x3,1)=size(find(data5==1),1)/size(find(data5>1),1); % criteria minimise overlap of ellipses
                    data3(2,x3,1)=mean(areas(:,2)./areas(:,1));% criteria minimise average % overlap of ellipses
%                     close(f1)
%                     close(f2)
                end
            else % measure average separation of means
                for x3 = 1:S1
                    for x4 = 1:S1
                        for x5 = 1:size(PCS,2)
                            data4(x3,x4)=data4(x3,x4)+abs(data3(1,x3,x5)-data3(1,x4,x5));
                        end
                        %data4(x3,x4)=data4(x3,x4)^0.5;
                    end
                    data3(2,x3,1)=sum(data4(x3,:));
                end                                
            end
            
            % Calculate average distance between training and test sets
            data4 = [];
            data4(R2)=0;
            for x3 = 1:S1
                for x4 = 1:R2
                    for x5 = 1:size(PCS,2)
                        data4(x4)=data4(x4)+abs(TestScores(x4+R2*(x3-1),PCS(x5))-data3(1,x3,x5));
                    end
                    %data4(x4)=data4(x4)^0.5;
                end
                data3(3,x3,1)=sum(data4);
                data4(:)=0;
            end
            
            % Calculation to make decision on
            % Value based upon absolute values
            % Criteria for checking to make sure model is still robust
            %             for x3=1:size(M2,1)
            %                 if sum(M2(x3,:))<size(M2,2)-1*(size(PCS,2)-1) %Change number here to small substractions to make more robust selection
            %                     data3(2,:,1)=0;
            %                 end
            %             end
            if sum(sum(M2>dataX(3:end,:)))>size(PCS,2) % Checks to see if new model has more test points outside confidence limit than original
                data3(2,:,1)=0;
            end
            output(x1,x2)=sum(data3(2,:,1));
            % Value based upon % change
            %output(x1,x2)=sum(sum((data3(2:3,:,1)-dataX)./dataX,2).*[-1;1]);
        else
            output(x1,x2)=NaN;
        end
    end
    % Make and implement decision
    x1
    data1(:,find(output(x1,:)==max(output(x1,:))))=0;
    
end

%% Review

output(:,end+1)=max(output,[],2);



